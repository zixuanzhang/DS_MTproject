---
title: "ClassifyMethod_EZ"
author: "Eleanor Zhang"
date: "5/9/2019"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width = 7,fig.asp = .7,out.width = "90%",
                      message = FALSE, warning = FALSE)
library(tidyverse)
library(caret)
library(boot)
library(corrplot)
library(glmnet)
library(splines)
library(mgcv)
library(RColorBrewer)
library(MASS) # contain data
library(mlbench) 
library(pROC) # generate ROC curve
library(AppliedPredictiveModeling)
library(ggpubr)
theme_set(theme_classic())
```

## Data 

Binary outcome: high rating = 1
```{r}
apple <- read_csv("./data/AppleStore.csv") %>%
  janitor::clean_names() %>%
  dplyr::select(-c(x1, id, track_name, currency, ver)) %>%
  mutate(size_bytes = round(size_bytes * 1e-6),
         cont_rating = factor(cont_rating, levels = c("4+", "9+","12+","17+")),
         user_rating = factor(ifelse(user_rating >= 4, "high", "med.low"), levels = c("med.low","high"))) %>%
  rename(size_megabytes = size_bytes) %>%
  filter(rating_count_tot != 0,
         user_rating_ver != 0) %>% #Remove apps with no user rating
  mutate(prime_genre = as.integer(ifelse(prime_genre == "Games", 1, 0))) %>% 
  dplyr::select(-rating_count_tot, -rating_count_ver, -vpp_lic) #vpp_lic has nearzero variance

str(apple)
contrasts(apple$user_rating)
table(apple$user_rating)
```

split data into train and test
```{r}
set.seed(1234)
#Split data to traning and testing
trRows = createDataPartition(apple$user_rating,
                             p = .75,
                             list = FALSE)
train_data = apple[trRows,]
test_data = apple[-trRows,]
#in matrix form
x_train = model.matrix(user_rating~., train_data)[,-1] 
y_train = train_data$user_rating
x_test = model.matrix(user_rating~., test_data)[,-1] 
y_test = test_data$user_rating

ctrl1 = trainControl(method = "cv", number = 10)
```

continous outcome
```{r}
apple1 <- read_csv("./data/AppleStore.csv") %>%
  janitor::clean_names() %>%
  dplyr::select(-c(x1, id, track_name, currency, ver)) %>%
  mutate(size_bytes = round(size_bytes * 1e-6),
         cont_rating = factor(cont_rating, levels = c("4+", "9+","12+","17+")))%>%
  rename(size_megabytes = size_bytes) %>%
  filter(rating_count_tot != 0,
         user_rating_ver != 0) %>% #Remove apps with no user rating
  mutate(prime_genre = as.integer(ifelse(prime_genre == "Games", 1, 0))) %>% 
  dplyr::select(-rating_count_tot, -rating_count_ver, -vpp_lic) #vpp_lic has nearzero variance

train_data1 = apple1[trRows,]
test_data1 = apple1[-trRows,]
#in matrix form
x_train1 = model.matrix(user_rating~., train_data1)[,-1] 
y_train1 = train_data1$user_rating
x_test1 = model.matrix(user_rating~., test_data1)[,-1] 
y_test1 = test_data1$user_rating
```

## Data descriptions and EDA

size megabytes is right skewed, mostly less than 1000 mb;  
price is right skewed, most less than $10;  
overall user rating is left skewed; recode into binary variable as either high rating(>= 4) or low (<4) user rating of current version

continous
```{r}
transparentTheme(trans = .4)
featurePlot(x = apple[, c(1,2,4,7,8,9)], # all features are numeric
            y = factor(apple$user_rating), # binary variable
            scales = list(x = list(relation="free"), 
                        y = list(relation="free")), # set both x and y scales to be free
            plot = "density", # density plot for each variable; 
            pch = "|",  # set the marker
            auto.key = list(columns = 3))
```

categorical
```{r}
# aggregate(user_rating ~ cont_rating + prime_genre, data = apple, mean)
apple %>% mutate(user_rating = factor(user_rating),
                 prime_genre = factor(prime_genre)) %>% 
  group_by(user_rating, prime_genre, cont_rating) %>% 
  summarize(n = n()) %>% 
  ggplot(aes(x = cont_rating, y = n))+
  geom_bar(aes(fill = prime_genre), stat = "identity", color = "white",
        position = position_dodge(0.9)) + facet_wrap(~user_rating) + fill_palette("jco") +
  labs(x = "content rating") +
  scale_fill_discrete(name="Primary Genre of app",
                         breaks=c("0", "1"),
                         labels=c("NonGames", "Games"))
```


## Methods

```{r}
library(rpart) # for recursive partition (CART: Classfification and Regression Tree)
library(rpart.plot) # better tool to visualze CART tree
library(party) # conditional inference tree (stopping criterion is based on permutation test; problem of early stoppoing)
library(partykit) # visualize party object
library(randomForest) # random Forest; could be slow
library(ranger) # C++ improvement on randomForest; much faster for tuning paremeter
library(gbm) # gradient boosting machine (boosting)
library(plotmo) 
library(pdp) # create partial dependence plot
library(lime)
```

### CART: regression tree 
use only caret package to tune

```{r}
ctrl1 = trainControl(method = "cv", number = 10) # very slow
```

Tune Cp: best = 0.002
```{r}
set.seed(1234)
# tune over cp, method = "rpart"
rpart.fit <- train(user_rating~., train_data1, 
                   method = "rpart",
                   tuneGrid = data.frame(cp = exp(seq(-10,-4, length = 20))), # try many values here
                   trControl = ctrl1)
ggplot(rpart.fit, highlight = TRUE)
rpart.fit$bestTune # 0.002
rpart.plot(rpart.fit$finalModel)
```

tune maximum depth : best = 5
```{r}
set.seed(1234)
rpart2.fit <- train(user_rating~., train_data1, 
                   method = "rpart2",
                   tuneGrid = data.frame(maxdepth = 1:10), 
                   trControl = ctrl1)
ggplot(rpart2.fit, highlight = TRUE)
rpart2.fit$bestTune # depth = 5
rpart.plot(rpart2.fit$finalModel)
```

### Conditional inference tree (regression)

stopping criterion is p value; at each step, the splitting rule is selected as the variable with strongest association with response. 
*  pros: Avoid variable selection bias towards predictors with many possible cut points; ensures the right size tree is grown without additional pruning or cross validation, 
*  cons: can stop early. 
Tune: `mincriterion` (1- p.value)  

```{r}
set.seed(1234)
ctree.fit <- train(user_rating~., train_data1, 
                   method = "ctree",
                   tuneGrid = data.frame(mincriterion = 1-exp(seq(-7, -2, length = 30))),
                   trControl = ctrl1)
ggplot(ctree.fit, highlight = TRUE)
ctree.fit$bestTune # 1 - p.value = 0.932
plot(ctree.fit$finalModel)
```


### CART: classfication tree 

use caret package only

Tune Cp
```{r}
ctrl2 <- trainControl(method = "cv",
                     summaryFunction = twoClassSummary, # use ROC curve as summary
                     classProbs = TRUE)

set.seed(1234)
rpart.fit.bin <- train(user_rating~., apple, 
                   subset = trRows,
                   method = "rpart",
                   tuneGrid = data.frame(cp = exp(seq(-6,-3, len = 30))), 
                   trControl = ctrl2,
                   metric = "ROC")

ggplot(rpart.fit.bin, highlight = TRUE)
rpart.fit.bin$bestTune # cp = 0.0037, treesize = 7
rpart.fit.bin$finalModel$cptable # look at the last row : treesize = nsplit + 1 = 6 + 1
rpart.plot(rpart.fit.bin$finalModel) 
```

### Conditional Inference tree (classifcation)

```{r}
set.seed(1234)
ctree.fit.bin <- train(user_rating~., apple, 
                   subset = trRows,
                   method = "ctree",
                   tuneGrid = data.frame(mincriterion = 1-exp(seq(-4, -1, length = 30))), # 1-alpha
                   metric = "ROC",
                   trControl = ctrl2)
ggplot(ctree.fit.bin, highlight = TRUE)
ctree.fit.bin$bestTune # 1- p.value = 0.894
plot(ctree.fit.bin$finalModel)
```

### SVM (caret)


linear: SVM linear
```{r}
library(e1071)
set.seed(1234)
svml.fit <- train(user_rating~., 
                  data = apple[trRows,], 
                  method = "svmLinear2", # use method from e1017 package; linear SVM
                  preProcess = c("center", "scale"), # very important
                  tuneGrid = data.frame(cost = exp(seq(-5,2,len=30))),
                  trControl = ctrl1)

ggplot(svml.fit, highlight = TRUE) # use accuracy and Kappa to evaluate; no probability; no ROC curve
svml.fit$bestTune # 1.363895
```

radial kernel: nonlinear SVM
```{r}
# try as much as possible the tuning grid
svmr.grid <- expand.grid(C = exp(seq(-5,2,len=20)),
                         sigma = exp(seq(-8,-3,len=5))) # gamma in SVM function
set.seed(1234)             
svmr.fit <- train(user_rating~., apple, 
                  subset = trRows,
                  method = "svmRadial", # from package kernal lab
                  preProcess = c("center", "scale"),
                  tuneGrid = svmr.grid,             
                  trControl = ctrl1)
 
ggplot(svmr.fit, highlight = TRUE) 
```

### SVM (for plot)

linear boundary
```{r}
set.seed(1234)
# use CV to select
linear.tune <- tune.svm(user_rating~., 
                        data = apple[trRows,], 
                        kernel = "linear",  # no transformation; linear boundaries; 
                        cost = exp(seq(-5,2,len=30))) # one tuning parameter C
summary(linear.tune)
plot(linear.tune) # look at CV result

best.linear <- linear.tune$best.model # extract best model
summary(best.linear) # look at the best model; C classfication

# get predicted label
pred.linear <- predict(best.linear, newdata = apple[-trRows,])
pred.linear
# SVM does not provide estimated probability, so we will use matrix:

# look at prediction performance by accuracy and Kappa measures
confusionMatrix(data = pred.linear, 
                reference = apple$user_rating[-trRows]) # accuracy = 0.8533

plot(best.linear, apple[trRows,], # plot SVM object
     size_megabytes~user_rating_ver, # pick 2 predictors to plot
     slice = list(price = 3.99, cont_rating = "4+", # fix 6 other covariates such as to visualize
                  prime_genre = 0, sup_devices_num = 36,
                  ipad_sc_urls_num = 5, lang_num = 5),
                  symbolPalette = c("orange","darkblue"), # change the color of data points
                  color.palette = terrain.colors)
```

radial boundary
```{r}
set.seed(1234)
# 10 fold validation; center and scale by default
radial.tune <- tune.svm(user_rating~., 
                        data = apple[trRows,], 
                        kernel = "radial", 
                        cost = exp(seq(-5,2,len=20)), # for all SVM method
                        gamma = exp(seq(-8,-3,len=5))) # for radial kernel parameter

summary(radial.tune)
plot(radial.tune)

best.radial <- radial.tune$best.model
summary(best.radial) # best model

pred.radial <- predict(best.radial, newdata = dat[-rowTrain,])

# look at accuracy of this model
confusionMatrix(data = pred.radial, 
                reference = dat$diabetes[-rowTrain]) # better than linear kernel

plot(best.radial, dat[rowTrain,], glucose~pressure,
     slice = list(pregnant = 5, triceps = 20,
                  insulin = 20, mass = 25,
                  pedigree = 1, age = 40),
     symbolPalette = c("orange","darkblue"),
     color.palette = terrain.colors)
     
```

### predict on test data (regression)

```{r}
rpart.pred <- predict.train(rpart.fit, newdata = apple1[-trRows,]) # CART tree: Cp
rpart.pred2 <- predict.train(rpart2.fit, newdata = apple1[-trRows,]) # CART tree: maximum depth
ctree.pred <- predict.train(ctree.fit, newdata = apple1[-trRows,]) # ctree
```


### predict on test data (classification)

```{r}
# predict on further tuning on cost complexity
rpart.pred.bin <- predict(rpart.fit.bin, newdata = apple[-trRows,], 
                      type = "prob")[,1] # probability
# predict on ctree
rpartc.pred.bin <- predict(ctree.fit.bin, newdata = apple[-trRows,],
                       type = "prob")[,1]
```


## Cluster and PCA (entire dataset)

```{r}
library(factoextra) # fviz_() functions
library(gridExtra)
library(gplots)
```

prepare data
```{r}
dat <- read_csv("./data/AppleStore.csv") %>%
  janitor::clean_names() %>%
  dplyr::select(-c(x1, id, currency, ver)) %>%
  mutate(size_bytes = round(size_bytes * 1e-6),
         cont_rating = factor(cont_rating, levels = c("4+", "9+","12+","17+")),
         user_rating_bin = factor(ifelse(user_rating >= 4, "high", "med.low"), levels = c("med.low","high"))) %>%
  rename(size_megabytes = size_bytes) %>%
  filter(rating_count_tot != 0,
         user_rating_ver != 0) %>% #Remove apps with no user rating
  mutate(prime_genre = as.integer(ifelse(prime_genre == "Games", 1, 0))) %>% 
  dplyr::select(-rating_count_tot, -rating_count_ver, -vpp_lic) %>% 
  distinct(track_name, .keep_all = TRUE)

str(dat)
dat1 <- dat[, c(2,3, 5,8:10)]
str(dat1)
dat1 <- scale(dat1) # very important to scale data first
rownames(dat1) <- dat$track_name # for dendrogram plotting
```

### K means clustering

```{r}
# this function determines the optimal number of clusters(for reference, there is no truth)
fviz_nbclust(dat1,
             FUNcluster = kmeans,
             method = "silhouette") # three methods can be used; 
set.seed(1234) # the initial group assignment matters
km <- kmeans(dat1, centers = 3, nstart = 20) # try 20 different initial values

km_vis <- fviz_cluster(list(data = dat1, cluster = km$cluster),  
                       ellipse.type = "convex", # boundary shapes
                       geom = "point",
                       #geom = c("point","text"),
                       labelsize = 5, 
                       palette = "Dark2") + labs(title = "K-means") 

km_vis # Plot fisrt 2 PC

# outlier
dat %>% filter(str_starts(track_name, "Proloquo2Go")) %>% View
```

### Hierarchical clustering

```{r}
hc.complete <- hclust(dist(dat1), method = "complete")
hc.average <- hclust(dist(dat1), method = "average")
hc.single <- hclust(dist(dat1), method = "single")
hc.centroid <- hclust(dist(dat1), method = "centroid")
```

dendrogram

```{r}
fviz_dend(hc.complete, k = 3,   # make cut at forming 2 clusters    
          cex = 0.3, 
          palette = "jco", 
          color_labels_by_k = TRUE, # color the label
          rect = TRUE, rect_fill = TRUE, rect_border = "jco", # draw rectangles
          labels_track_height = 2.5) # label size

ind4.complete <- cutree(hc.complete, 4) # divide into 4 clusters; return the cluster assignment to each observation
ind4.complete
# Who are in the fourth cluster?
dat[ind4.complete == 4,]
```

more details
```{r}
display.brewer.all(n=NULL, type="all", select=NULL, exact.n=TRUE)
col1 <- colorRampPalette(brewer.pal(9, "GnBu"))(100)
col2 <- colorRampPalette(brewer.pal(3, "Spectral"))(2)

heatmap.2(t(dat1), # use transposed dataset
          col = col1, keysize=.8, key.par = list(cex=.5),
          trace = "none", key = TRUE, cexCol = 0.75, 
          labCol = as.character(dat[,1]),
          ColSideColors = col2[as.numeric(dat[,"Legendary"])+1],
          margins = c(10, 10))
```

### PCA

```{r}
pca <- prcomp(dat1) # perform PCA
pca$rotation # PC directions 
pca$sdev # square this will be variation explained by each PC; usually decreasing
pca$rotation %*% diag(pca$sdev) # correlation loading; correlation between each variable to PC direction
corrplot(pca$rotation %*% diag(pca$sdev))

var <- get_pca_var(pca) # get diff information about variables
corrplot(var$cor)
```

percent explained bye each PC
```{r}
fviz_eig(pca, addlabels = TRUE)
```

PC components, variable contribution
```{r}
# the contribution of each var = rotation^2 to each PC
a <- fviz_contrib(pca, choice = "var", axes = 1) # PC1
b <- fviz_contrib(pca, choice = "var", axes = 2) # PC2
grid.arrange(a, b, nrow = 2)

# check this on PC1
pca$rotation[,1]^2
```


```{r}
# on the plot, the x axis(PC1) is correlation loading of each variable to PC1
fviz_pca_biplot(pca, axes = c(1,2), # number of PC, use first two
                habillage = dat$user_rating_bin, # groups
                label = c("var"), # only label variable names
                addEllipses = TRUE) # boundary of groups
# legendary tend to have high special attack, attack and defence

fviz_pca_var(pca, col.var = "steelblue", repel = TRUE) # if p = 2, then a circle

# for individual
fviz_pca_ind(pca,
             habillage = dat$user_rating_bin,
             label = "none",
             addEllipses = TRUE)
```

