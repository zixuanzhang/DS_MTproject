---
title: "EDA"
author: "Eleanor Zhang"
date: "3/23/2019"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(caret)
library(boot)
library(corrplot)
library(pls)
library(glmnet)
```

## Read data 

Read data
```{r}
apple <- read_csv("./data/AppleStore.csv") %>% 
  janitor::clean_names() 

str(apple) # 7197 observations 17 variables (including response)
unique(apple$currency) # all price on USD unit, so remove this

apple <- apple %>% 
  select(-c(x1, track_name, id, currency, ver)) # %>% 

  
 # mutate(cont_rating = factor(cont_rating, levels = c("4+", "9+", "12+", "17+")),
         #prime_genre = as.factor(prime_genre))
  
summary(apple)
anyNA(apple) # no missing values
str(apple) # select 11 covariables 
```


Response: user_rating  

Predictors might be used:  
user_rating: Average User Rating value (for all version)
Predictors: 

1.	size_bytes: Size (in Bytes)
2.	price: Price amount ($)
3.	rating_count_tot: User Rating counts (for all version)
4.	rating_count_ver: User Rating counts (for current version)
5.	user_rating_ver: Average User Rating value (for current version)
6.	ver: Latest version code (removed)
7.	cont_rating: Content Rating
8.	prime_genre: Primary Genre
9.	sup_devices.num: Number of supporting devices
10.	ipadSc_urls.num: Number of screenshots shown for display
11.	lang.num: Number of supported languages
12.	vpp_lic: Vpp Device Based Licensing Enabled

## EDA

```{r}
# predictor pool
x <- model.matrix(user_rating ~., data = apple)[,-1] # remove the intercept column; design matrix
x
dim(x)
# response
y <- apple$user_rating
unique(y)
```

feature plot
```{r}
theme1 <- trellis.par.get()
theme1$plot.symbol$col <- rgb(.2, .4, .2, .5)
theme1$plot.symbol$pch <- 16
theme1$plot.line$col <- rgb(.8, .1, .1, 1)
theme1$plot.line$lwd <- 2
theme1$strip.background$col <- rgb(.0, .2, .6, .2)
trellis.par.set(theme1)
featurePlot(x, y, plot = "scatter", labels = c("","Y"),
            type = c("p"), layout = c(5,2)) # ???? 
```

correlation plot excluding two factor variables : content rating and genre
```{r}
apple <- apple %>% select(user_rating, everything())
pairs(apple[-c(7,8)])

appleCor <-  cor(apple[-c(7,8)]) # correlation matrix of the modified dataset above
summary(appleCor[upper.tri(appleCor)]) # summary
findCorrelation(appleCor, cutoff = .75)

appleCor > 0.75 # user rating (all version) and user rating (current version)

corrplot(cor(x), method = "circle",tl.cex = 0.5)

table(apple$prime_genre) # games are oversampled
table(apple$cont_rating) # 4+ is oversampled
```

Comment: correlation between covariates are not significant; user rating and user rating version are highly correlated. (0.77)
Games, 4+ rating are oversampled

check linear dependency of numerical predictors (no problematic predictors)
```{r}
nzv <- nearZeroVar(apple) # nzv: near zero variance
dim(apple[, -nzv])
```

## Fit model

#### variable selection: ridge and lasso

ridge regression
```{r}
ridge.mod <- glmnet(x, # design matrix (will be standardized by glmnet by default)
                    y, # response
                    alpha = 0, # ridge regression
                    lambda = exp(seq(-1, 10, length=100)))
# use cv to select lambda

set.seed(1234)
# by default, use 10 fold cv
cv.ridge <- cv.glmnet(x, y, 
                      alpha = 0, 
                      lambda = exp(seq(-10, 6, length=100)), 
                      type.measure = "mse")

plot(cv.ridge) 
cv.ridge$lambda.min
predict(cv.ridge, s="lambda.min", 
        type="coefficients")
```

lasso regression
```{r}
# return the final model
cv.lasso <- cv.glmnet(x,y, alpha = 1, # lasso method
                      lambda = exp(seq(-10, 6, length=100)))
# find the lambda that gave the smallest test MSE
plot(cv.lasso)
cv.lasso$lambda.min # 0.011
predict(cv.lasso, s="lambda.min", 
        type="coefficients")
```

elastic net
```{r}
set.seed(1234)
ctrl1 <- trainControl(method = "repeatedcv", # 10 fold CV for 5 times, then average result
                      number = 10, repeats = 5)
enet.fit <- train(x, y,
                     method = "glmnet",
                     tuneGrid = expand.grid(alpha = seq(0, 1, length = 5), #0,0.25,0.5,0.75,1
                                            lambda = exp(seq(-10, 6, length=50))),
                   # preProc = c("center", "scale"),
                     trControl = ctrl1)
enet.fit$bestTune # best alpha = 1 (lasso), best lambda = 0.0117

ggplot(enet.fit)
```

#### nonlinear

```{r}

```

#### PCR

```{r}
set.seed(1234)
# index for the row of training data
trRows <- createDataPartition(apple$user_rating,
                              p = .75,
                              list = F)

# training data
# matrix of predictors (glmnet uses input matrix)
x_train <- model.matrix(user_rating ~., apple)[trRows,-1] # glmnet() make design matrix, exclude the intercept
x_train
# vector of response(train)
y_train <- apple$user_rating[trRows]

# test data
x_test <- model.matrix(user_rating ~., apple)[-trRows,-1]
y_test <- apple$user_rating[-trRows]
```

```{r}
set.seed(1234) # can try other seed

# pcr take argument as formula
pcr.mod <- pcr(user_rating~.,  # formula
               data = apple[trRows,], # only use training data; or use subset = __
               scale = TRUE, # recommended to scale all predictors before PCR, the default is False
               # center = FALSE, by default
               validation = "CV")  # 10 CV, or use "LOO"
# another argument: ncomp = ___, if not specified, model will fit for all predictors

summary(pcr.mod) # CV and adj CV (unbiased one after adjusting for the method)
pcr.mod$model
pcr.mod$fitted.values
validationplot(pcr.mod, val.type="MSEP", # type of validation result (MSE prediction), or RMSEP (square root)
               legendpos = "topright") # ncomp = 32 gives the smallest MSEP

# test MSE
predy2.pcr <- predict(pcr.mod, newdata = x_test, ncomp = 32)
mean((predy2.pcr-y_test)^2) # 0.898
View(pcr.mod$coefficients)
```

#### Lasso (for variable selection)


#### linear

```{r}
lm1 <- lm(user_rating ~., data = apple)
summary(lm1) # 34 components
```

```{r}
hist(apple$user_rating)
```

