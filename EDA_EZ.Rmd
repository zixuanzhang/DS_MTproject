---
title: "EDA"
author: "Eleanor Zhang"
date: "3/23/2019"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width = 7,fig.asp = .7,out.width = "90%",
                      message = FALSE, warning = FALSE)
library(tidyverse)
library(caret)
library(boot)
library(corrplot)
library(pls)
library(glmnet)
```

## Read and clean data 

Read data
```{r}
apple <- read_csv("./data/AppleStore.csv") %>% 
  janitor::clean_names() 

str(apple) # 7197 observations 17 variables (including response)
unique(apple$currency) # all price on USD unit, so remove this

apple <- apple %>% 
  select(-c(x1, track_name, id, currency, ver)) # remove 

summary(apple)
anyNA(apple) # no missing values
str(apple) # select 11 covariables 
```


Response: user_rating  

__user_rating__: Average User Rating value (for all version)

Predictors: 

1.	size_bytes: Size (in Bytes)
2.	price: Price amount ($)
3.	rating_count_tot: User Rating counts (for all version)
4.	rating_count_ver: User Rating counts (for current version)
5.	user_rating_ver: Average User Rating value (for current version)
6.	cont_rating: Content Rating
7.	prime_genre: Primary Genre
8.	sup_devices.num: Number of supporting devices
9.	ipadSc_urls.num: Number of screenshots shown for display
10.	lang.num: Number of supported languages
11.	vpp_lic: Vpp Device Based Licensing Enabled

## EDA

```{r}
# predictor pool
x <- model.matrix(user_rating ~., data = apple)[,-1] # remove the intercept column; design matrix
x
dim(x)
# response
y <- apple$user_rating
unique(y)
```

feature plot
```{r}
theme1 <- trellis.par.get()
theme1$plot.symbol$col <- rgb(.2, .4, .2, .5)
theme1$plot.symbol$pch <- 16
theme1$plot.line$col <- rgb(.8, .1, .1, 1)
theme1$plot.line$lwd <- 2
theme1$strip.background$col <- rgb(.0, .2, .6, .2)
trellis.par.set(theme1)
featurePlot(x, y, plot = "scatter", labels = c("","Y"),
            type = c("p"), layout = c(5,2)) # ???? 
```

correlation plot excluding two factor variables : content rating and genre
```{r}
apple <- apple %>% select(user_rating, everything())
pairs(apple[-c(7,8)])

appleCor <-  cor(apple[-c(7,8)]) # correlation matrix of the modified dataset above
summary(appleCor[upper.tri(appleCor)]) # summary
findCorrelation(appleCor, cutoff = .75)
appleCor

appleCor > 0.75 # user rating (all version) and user rating (current version)

corrplot::corrplot(cor(x), method = "circle",tl.cex = 0.5)

table(apple$prime_genre) # games are oversampled
table(apple$cont_rating) # 4+ is oversampled
```

Comment: correlation between covariates are not significant; user rating and user rating version are highly correlated. (0.77)
Games, 4+ rating are oversampled

check linear dependency of numerical predictors (no problematic predictors)
```{r}
nzv <- nearZeroVar(apple) # nzv: near zero variance
dim(apple[, -nzv])
```

split into train and test data
```{r}
set.seed(1234)
trRows <- createDataPartition(apple$user_rating, # vector of outcomes
                              p = .80, # percentage of training data (random assign)
                              list = FALSE) # in a matrix form 
trRows

# train data
x_train <- model.matrix(user_rating ~., data = apple[trRows,])[,-1] 
x_train
dim(x_train) # 5759
y_train <- apple[trRows,]$user_rating
unique(y_train)

# test data
x_test <- model.matrix(user_rating ~., data = apple[-trRows,])[,-1] 
x_test
dim(x_test) # 1438
y_test <- apple[-trRows,]$user_rating
unique(y_test)
```


## Fit model

### variable selection: ridge and lasso

ridge regression: we have large number of predictors(including categorical variables, so lots of dummy variables)

use ridge regression from `glmnet` package
```{r}
# ridge regression with 100 tuning parameter values (model formula)
ridge.model <- glmnet(x_train, y_train, alpha = 0, lambda = exp(seq(-10, 6, length = 100)))
```

use 10 fold CV to select tuning para.
```{r}
set.seed(1234)
cv.ridge <- cv.glmnet(x_train, y_train, alpha = 0, lambda = exp(seq(-10, 6, length = 100)), 
                      type.measure = "mse")

# plot CV result as a function of tuning para.
plot(cv.ridge)

# optimal lambda:
cv.ridge$lambda.min # 0.00492
# 1SE lambda:
cv.ridge$lambda.1se # 0.28
```

obtain coefficients of ridge model: optimal and sparse
```{r}
# use the optimal:
best.lambda <- cv.ridge$lambda.min
predict(ridge.model, s = best.lambda, type = "coefficients") # on original scale

# use sparse model:
best.1se.lambda <- cv.ridge$lambda.1se
predict(ridge.model, s = best.1se.lambda, type = "coefficients")
```

predict on ridge model
```{r}
pred.ridge <- predict(ridge.model, s = best.lambda, newx = x_test, type = "response")
# MSE
sum((y_test - pred.ridge)^2) / length(y_test) # 0.829
```


lasso regression
```{r}

```

elastic net
```{r}

```

#### nonlinear

```{r}

```

#### PCR

```{r}
set.seed(1234)
# index for the row of training data
trRows <- createDataPartition(apple$user_rating,
                              p = .75,
                              list = F)

# training data
# matrix of predictors (glmnet uses input matrix)
x_train <- model.matrix(user_rating ~., apple)[trRows,-1] # glmnet() make design matrix, exclude the intercept
x_train
# vector of response(train)
y_train <- apple$user_rating[trRows]

# test data
x_test <- model.matrix(user_rating ~., apple)[-trRows,-1]
y_test <- apple$user_rating[-trRows]
```

```{r}
set.seed(1234) # can try other seed

# pcr take argument as formula
pcr.mod <- pcr(user_rating~.,  # formula
               data = apple[trRows,], # only use training data; or use subset = __
               scale = TRUE, # recommended to scale all predictors before PCR, the default is False
               # center = FALSE, by default
               validation = "CV")  # 10 CV, or use "LOO"
# another argument: ncomp = ___, if not specified, model will fit for all predictors

summary(pcr.mod) # CV and adj CV (unbiased one after adjusting for the method)
pcr.mod$model
pcr.mod$fitted.values
validationplot(pcr.mod, val.type="MSEP", # type of validation result (MSE prediction), or RMSEP (square root)
               legendpos = "topright") # ncomp = 32 gives the smallest MSEP

# test MSE
predy2.pcr <- predict(pcr.mod, newdata = x_test, ncomp = 32)
mean((predy2.pcr-y_test)^2) # 0.898
View(pcr.mod$coefficients)
```

#### Lasso (for variable selection)


#### linear

```{r}
lm1 <- lm(user_rating ~., data = apple)
summary(lm1) # 34 components
```


